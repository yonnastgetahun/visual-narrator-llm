# Visual Narrator LLM ğŸ¥â†’ğŸ“

## Project Goal
Create a state-of-the-art 3B parameter LLM specialized in generating vivid audio descriptions for visual media.

## Current Status
ğŸ¯ **Phase 1: Practice & Setup - COMPLETED âœ…**
- âœ… Environment setup completed
- âœ… Python 3.12 compatibility verified
- âœ… Data loading pipelines tested and working
- âœ… Conceptual Captions dataset accessible
- ğŸš€ **READY FOR FIRST TRAINING RUN**

## Recent Achievements
- Solved Python 3.12 package compatibility issues
- Established working development environment
- Successfully tested multiple dataset loaders:
  - âœ… Wikitext (text)
  - âœ… Conceptual Captions (image URLs + captions)
  - âœ… CIFAR-10 (images)

## Immediate Next Step
Running first training script: `training/train_conceptual.py`

## Architecture Plan
- **Base Model**: 3B parameter decoder-only transformer
- **Training**: Pre-training on Common Crawl + specialized fine-tuning
- **Target**: SOTA performance on audio description tasks

## Technical Stack
- PyTorch 2.0+
- Hugging Face Transformers
- Hugging Face Datasets
- Conceptual Captions dataset (practice phase)
